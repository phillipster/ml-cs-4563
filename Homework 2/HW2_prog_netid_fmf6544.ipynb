{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZhdsgaGL_Uy"
   },
   "source": [
    "# Programming Assignment 2 - Polynomial Regression (50 points) on Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q11_3rfL_U1"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "For this semester, the teaching staff of this course will be using Autograder to grade programming assignment. Here are three things we would like you to know before starting. `PLEASE READ CAREFULLY.` Otherwise, you might lose points on some questions.\n",
    "\n",
    "* If you see any blocks containing statements like `grader.check(\"Qxx\")`, please `do not modify` them. You can add new cells to the notebook, but just make sure there is `no other cells` between the answer cells containing tag `# TODO Qxx` and grading cells like 'grader.check(\"Qxx\")`. \n",
    "\n",
    "* If the instructions say that you are required to use certain names for output variables, please `follow the instructions`, and you are not supposed to change the names of any given variables. You can still create new variables, but don't forget to `assign the output variables to correct values`. If the `type` of a output variable is specified, make sure the type of the variable is correct.\n",
    "\n",
    "* You can use print statements to print out results through out the notebook. However, if you have any `print statements in functions`, please make sure you have `put them in comments` before you submit.\n",
    "\n",
    "* Please note for questions that require you to plot, please **_DO NOT MODIFY_** statements like `plt.show(block=False)`. Changing the statement would block the execution of autograder and you might lose points on that question.\n",
    "\n",
    "* Please `APPEND YOUR NYU NETID` to the name your submission (for example, name your submission as \"HW1_prog_abc12345.ipynb\" when you submit on Gradescope, and replace <abc1234> with your NYU NetID). \n",
    "\n",
    "Good luck with programming assignment 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uew1yw1PL_U3"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, you will explore \n",
    "* polynomial transformations of the data set and the concept of overfitting \n",
    "* how regularization reduces overfitting for one of the polynomial transformations that overfit\n",
    "* how the training error and validation error change when the number of training examples increased. You will view these changes by plotting the learning curves.\n",
    "\n",
    "\n",
    "Due to the small number of training examples, if you play with the data set you will observe outcomes that are due to chance.  With a larger dataset things would be more stable.  \n",
    "We kept the number of examples small so it is easy to understand.  In high dimensionality we would expect the dataset to be more spread out than in our toy example for this homework assignment.  In this notebook, our training examples are in $1$-D.\n",
    "\n",
    "The assignment has four parts:\n",
    "* First part: you will read in the dataset and perform train/validation split, visualize the training and validation set, and write the regularized closed form solution that will be used in the other parts of this assignment.\n",
    "* Second part: you will perform univariate polynomial feature transformation and perform model selection.  In this part you will use the regularized closed form solution you wrote in part 1 with $\\lambda=0$.\n",
    "* Third part: you will take one of the overfitted models and observe what happens when you use $L2$ regularization when fitting the model.  In this part you will use the regularized closed form solution you wrote in part 1 with $\\lambda \\not=0$.\n",
    "* Fourth part: you will use take one of the polynomial transformations that resulted in overfitting and observe what happens when you train on more examples (unregularized).  In this part, you will used the reguarized closed form solution you wrote in part 1 with $\\lambda = 0$.\n",
    "\n",
    "In your final project, you will use feature transformation and regularization at the same time to select the best model.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VZPPlLVL_U4"
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD7xbMczXv5K"
   },
   "source": [
    "# For every question including graph, please run it and leave the graphs in your output before you turn in the hw, it makes grading much easier. Your TAs do appreciate your cooperation.\n",
    "### Points will be taken off if you don't display the graphs in your hw output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M56vwXBBL_U6"
   },
   "source": [
    "# Part 1\n",
    "## Preparing the Dataset\n",
    "\n",
    "### Importing Data \n",
    "Import data from `data_hw2.csv`. Please put `data_hw2.csv` file under the **_SAME DIRECTORY_** of your `HW2_prog_<netid>.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EEknecVL_U6"
   },
   "outputs": [],
   "source": [
    "# TODO Q01\n",
    "# Step 1: Read `data_hw2.csv` into `df` as a DataFrame object (i.e df(<pd.Dataframe>) )\n",
    "df = ...\n",
    "# Step 2: Convert `df' to a NumPy array (i.e data(<np.ndarray>) )\n",
    "data = ...\n",
    "# Step 3: Select the first column of `data` and put it in X(<np.ndarray>) \n",
    "#         Select the second column of `data' and put it in  in Y(<np.ndarray>)\n",
    "X = ...   # Select the first column of `data`\n",
    "y = ...   # Select the second column of `data`\n",
    "\n",
    "# Next, we set nu_samp to be the number of examples in the dataset\n",
    "nu_samp = X.shape[0]\n",
    "# Define `N` to be the 1/3 the number of original examples.  \n",
    "# In part 2 and 3  you will only use N training examples.  \n",
    "# In part 4 you will use 2N training examples.\n",
    "N = np.int_(nu_samp/3) # Integer division to make sure `N` is an integer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwK3vtOOL_U9"
   },
   "outputs": [],
   "source": [
    "# TODO Q02\n",
    "# Reshape X and y to be 2D matrices (i.e. rank-2 matrices)\n",
    "X_2d = ...  # Converts X from (N,) to (N,1)\n",
    "y_2d = ...  # Converts y from (N,) to (N,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_mfVmPIL_U_"
   },
   "source": [
    "### Training and Validation Set\n",
    "Set the training set to be the first 1/3 of the data and validation set to be the last 1/3 of the data.  (In parts 2 and 3 we won't use the full dataset). Normally we would have more data in the training set and less in the validation set.  However we are intentionally keeping the training set small so we can observe overfitting where the feature vector is $1$-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i92nVDIgL_VA"
   },
   "outputs": [],
   "source": [
    "##### TODO Q03 \n",
    "# Split X_2d and y_2d into training and validation sets\n",
    "\n",
    "# Save the first N rows into X_tr and y_tr\n",
    "X_tr = ...  # first N/3 rows of X_2d\n",
    "y_tr = ...  # first N/3 rows of y_2d\n",
    "\n",
    "# Save the last N rows for  X_val and y_val\n",
    "X_val = ...  # From index 2N until the end\n",
    "y_val = ...  \n",
    "\n",
    "# Note:\n",
    "# We will NOT use the examples in the range [N, 2N-1] (i.e., the middle third of the dataset) until later in this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxVPsc5NWtXv"
   },
   "source": [
    "The shape of X_tr should be (11,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBXle8GtL_VB"
   },
   "source": [
    "### Plotting Dataset\n",
    "\n",
    "By plotting the training and validation set, we can observe the training and validation set are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SV-2I37L_VC"
   },
   "source": [
    "Plot `X_tr` versus `y_tr` as a scatter plot. Make sure your plot has **grid lines**, a **_title_** and **_labels_** on axes. **_DO NOT MODIFY_** `plt.show(block=False)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oPIFpIQ7L_VD"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Q04\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRM3uaKSL_VD"
   },
   "outputs": [],
   "source": [
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-80, 85])\n",
    "# TODO Q04 \n",
    "# run this cell and observe the pattern of training data.\n",
    "plt.plot(X_tr,y_tr,'o')\n",
    "plt.title('y vs. X from training set')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoXZwc7qL_VG"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Now that we have looked at the training data, lets look at the validation data.\n",
    "\n",
    "Normally, we would not look at the validation set (or test set) until we use it to estimate how well our hypothesis will do in the future!  However, this assignment is about understanding how to use a validation set to select a model and we wanted you to observe that the validation set looks very similar to the training set.\n",
    "\n",
    "Plot `y_val` versus `X_val` as a scatter plot. Make sure your plot has **grid lines**, a **_title_** and **_labels_** on axes. **_DO NOT MODIFY_** `plt.show(block=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bc87dhypL_VH"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Q05\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qguJxk9UL_VI"
   },
   "outputs": [],
   "source": [
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-80, 85])\n",
    "\n",
    "# TODO Q05\n",
    "# plot the graph\n",
    "...\n",
    "\n",
    "plt.title('y vs. X from validating set')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaxgRVTyL_VI"
   },
   "source": [
    "### Implement regularized linear regression\n",
    "\n",
    "For parts 2, 3, and 4 of this assignment, you will be using the *closed-form* solution for linear regression -- both the regularized and non-regularized versions -- to compute the weight vector ${\\bf w}$.\n",
    "\n",
    "#### What You Need to DO:\n",
    "* Implement the regularized closed form solution for linear regression.\n",
    "* When you wish to use the non-regularized closed form solution for linear regression, simply set $\\lambda = 0$.\n",
    "\n",
    "#### Mathematical Formula:\n",
    "Write the function `poly_regression` that takes as input a design matrix $X$ (whose first column is a column of ones), ${\\bf y}$ (the target vector) and $\\lambda$ (the regularization parameter) and returns $(X^TX + N \\lambda I')^{-1}X^T{\\bf y}$.  Here, as long as $\\lambda \\not=0$ the inverse of $(X^TX + N \\lambda I')$ exists. \n",
    "\n",
    "In *part 2* of this assignment, we will not use any regularization so we will set $\\lambda =0$.  Fortunately, for this example, $X^TX$ is invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJgtlEklL_VJ"
   },
   "outputs": [],
   "source": [
    "# Note, here we are using lambda1 instead of lambda because lambda is a reserved word in Python.\n",
    "def poly_regression(X,y,lambda1): # We are using X for the design matrix.  It might be that X is in Z-space\n",
    "    d = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    w = ...\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1sprJ3QL_VJ"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Part 2:\n",
    "\n",
    "## Polynomial Transformation and Model Selection.\n",
    "\n",
    " To ease the notational burden, we are using $x$ for $x_1$ in this section.\n",
    "\n",
    "\n",
    "In class we discussed polynomial regression.  Here we ask you to experiement with univariate polynomial regression (polynomial regression with one feature ${\\bf x}=[x]$).  That is learning a function $w_0+w_1x+w_2x^2+\\cdots + w_dx^d$ where $d$ is the the polynomial's highest degree.  We showed in class we can perform a feature transformation to $Z$-space:\n",
    "$$ w_0 + w_1\\phi_1(x)+w_2\\phi_2(x) + \\cdots + w_d\\phi_d(x),$$\n",
    "where $\\phi({\\bf x})=x^i$,  i.e. $z_i=x^i$. (For example: $x^2 = x\\cdot x$) Remember: we are learning a linear function in $Z$-space.\n",
    "\n",
    "In this part you will:\n",
    "*  Trying different polynomial transformations of the data and observe the effects of different transformations on the training error and the validation error.\n",
    "* Plot the different hypotheis and the training dataset to visually observe underfitting and overfitting\n",
    "* Plot the learning curve for different transformations\n",
    "* Use the validation error to select the best model\n",
    "\n",
    "See if you can spot the underfitting and the overfitting in some of the transformations.\n",
    "\n",
    "You will observe that after some of the transformations, the hypothesis didn't fit the traning data very well. \n",
    "\n",
    "You will observe that after some of the transformations, the hypothesis fit the training data very well, but the validation error is very large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82tislRiL_VK"
   },
   "source": [
    "###  Trying different polynomial transformations of the data and observe the effects of different transformations on the training error and the validation error.\n",
    "\n",
    "In the cell below write code to obtain polynomial regression models of different orders starting from linear regression i.e. `degree = 1` to higher degree models  `degree = 2 to 10`. \n",
    "\n",
    "In the following cell will perform the following:\n",
    "* Perform the polynomial tranformation of your data using Sklearn's `PolynomialFeatures`  <blockquote> \"Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\"</blockquote>\n",
    "Note that it automatically augments the feature vector with a one unless you set `include_bias = False`.\n",
    "* Fit the transformed data using the function you wrote in part 1 where you set $\\lambda = 0$ (i.e. no regularizaton)\n",
    "* For each transformation, compute the \n",
    " * MSE for the training set $\n",
    "\\frac{1}{|X_{\\text{tr, poly}}|} \\sum_{{\\bf x}^{(i)} \\in X_{\\text{tr, poly}}} \\left( g({\\bf x}^{(i)}) - y^{(i)} \\right)^2\n",
    "$  and \n",
    " * MSE for the validation set $\\frac{1}{|X_{\\text{tr, poly}}|} \\sum_{{\\bf x}^{(i)} \\in X_{\\text{tr, poly}}} \\left( g({\\bf x}^{(i)}) - y^{(i)} \\right)^2$\n",
    "\n",
    " Save these values in a list (`validation_costs` and `train_costs`)and save ${\\bf w}$ in a dictionary (`w_dict`)\n",
    "\n",
    "In the subsequent cell you will plot these errors vs degree of transformation. Afterwards, you will use the validion errors to determine the order that fits the data best. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEFxV8ZbL_VK"
   },
   "outputs": [],
   "source": [
    "lambda1 =0  # We set lambda1 = 0 since we are not using any regularization in part 2.\n",
    "\n",
    "# Record (store) the training error, validation error and w in train_costs(<list>), validation_costs(<list>) and w_dict(<dict>) for degrees = 1, 2, 3,..., 10 \n",
    "validation_costs_6 = []  \n",
    "train_costs_6 = []       \n",
    "w_dict_6 = {}\n",
    "\n",
    "model_degree = range(1,11) # The different feature transformatons we will perform\n",
    "\n",
    "for d in model_degree:\n",
    "    print('Order: ', d)\n",
    "    poly = PolynomialFeatures(d)\n",
    "    X_tr_poly = poly.fit_transform(X_tr) # transforms the training data\n",
    "    X_val_poly = poly.transform(X_val) # transforms the validation data\n",
    "    \n",
    "    # TODO Q06\n",
    "    # Use your function from part 1 to determine w. The design matrix is X_tr_poly and the target vector is y_tr and lambda1=0. \n",
    "    w = ...\n",
    "    w_dict_6[d] = ...  # save the value of w \n",
    "    \n",
    "    # predict yhat for the training data, compute E_in (MSE for the training data) and store E_in in train_costs\n",
    "    yhat = ...\n",
    "    E_in = ...\n",
    "    train_costs_6.append(...)  \n",
    "\n",
    "    # predict yhat_val for the validation data, compute E_val (MSE for the validation data) and store E_val in validation_costs\n",
    "    yhat_val = ...\n",
    "    E_val = ...\n",
    "    validation_costs_6.append(...) \n",
    "    \n",
    "    print('w: ', w)\n",
    "    print(\"X_tr_poly size:\", X_tr_poly.shape)\n",
    "    print(\"max:\", np.max(X_tr_poly))\n",
    "    print('E_in: ',E_in)\n",
    "    print(\"E_val:\", E_val)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK7-y13hW5V2"
   },
   "source": [
    "If your code works correctly, in Order 10, the last three outputs should be close to:\n",
    "\n",
    "max: 494013.81738478417\n",
    "\n",
    "E_in:  0.00011159579586721235\n",
    "\n",
    "E_val: 1645420.4645535438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ziga2l2L_VM"
   },
   "source": [
    "### Plot the different hypotheis and the training dataset to visually observe underfitting and overfitting\n",
    "\n",
    "\n",
    "Plot training dataset and the hypothesis function for each degree. Make sure your plot has **grid lines**, a **_title_** and **_labels_** on axes. **_DO NOT MODIFY_** `plt.show(block=False)`\n",
    "\n",
    "Do you observe any underfitting or overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ftLpFPcRL_VM"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Q07\n",
    "manual: true\n",
    "points: 10\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTVfDcNVL_VN"
   },
   "outputs": [],
   "source": [
    "# TODO Q07\n",
    "for d in model_degree:\n",
    "    plt.xlim([-5, 5])\n",
    "    plt.ylim([-80, 85])\n",
    "    print('Degree: ', d)\n",
    "    # Plot data\n",
    "    ...    # type the following line of code plt.plot(X_tr, y_tr, 'o')\n",
    "    \n",
    "    # Plot hypothesis as a line\n",
    "    poly = PolynomialFeatures(d)\n",
    "    xp = np.linspace(-5,5,200).reshape((200,1))\n",
    "    xp_d = poly.fit_transform(xp)\n",
    "    yp_hat = xp_d.dot(w_dict_6[d])\n",
    "    \n",
    "    # Plot hypothesis\n",
    "    plt.plot(xp,yp_hat)\n",
    "    plt.xlim(-5,5)\n",
    "\n",
    "    plt.title('Training data & model of degree '+ str(d))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl27JTxZL_VO"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Plot `train_cost` versus `Model order` and `validation_cost` versus `Model order`  as line plots with style of `'.-'` in one graph. Make sure your plot has **grid lines**, a **_title_** and **_labels_** on axes. **_DO NOT MODIFY_** `plt.show(block=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEmyxtYQL_VP"
   },
   "source": [
    "###  Plot the learning curve for different transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZyIIBx_L_VQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ylim(0,1)\n",
    "\n",
    "# TODO Q08\n",
    "plt.plot(...)   # Training Cost vs Model Order.  Complete the code so it looks like plt.plot(model_degree, train_costs, '.-')\n",
    "plt.plot(...)   # Validation Cost vs Model Order.\n",
    "\n",
    "plt.title('Training ans Validation Cost vs Model order')\n",
    "plt.xlabel('Model order')\n",
    "plt.ylabel('Training and Validation Cost')\n",
    "plt.grid(True)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UBUHSgxWL_VQ"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Q09\n",
    "manual: true\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkOK2eAGL_VR"
   },
   "source": [
    "###  Use the validation error to select the best model\n",
    "Next, determine which model had the smallest validation cost.\n",
    "\n",
    "(Hint: you can use the numpy function np.argmin(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nwn7QisVL_VS"
   },
   "outputs": [],
   "source": [
    "# TODO Q09\n",
    "imin = ...\n",
    "print(\"Estimated model order= {0:d}\".format(imin+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrAjLJspL_VS"
   },
   "source": [
    "# Part 3.  Adding L2 regularization after a polynomial transformation of degree 10\n",
    "\n",
    "There was extreme overfitting when you performed a polynomial transformation of degree 10 on the dataset.  Here we can observe that regularization can prevent some of the overfitting.  (Please note, we are using a very small dataset to demonstrate the ideas.)\n",
    "\n",
    "In part 3 you will follow a similar approach as you did in part 2.  Specifically you will:\n",
    "* A) Try different values of $\\lambda$ and observe the effects of different values of $\\lambda$ (i.e. different amounts of L2 regularization) on the training error and the validation error. For each value of $\\lambda$ you will save the training error, validation error, and ${\\bf w}$.\n",
    "* B) Plot the different hypothesis and the training dataset to visually observe the effect of L2 regularization\n",
    "* C) Plot the learning curve for different values of $\\lambda$ (i.e. different amounts of L2 regularization)\n",
    "\n",
    "See if you can observe how the L2 regularization is affecting the fit of the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIfAasSBL_VT"
   },
   "source": [
    "### A) Try different values of $\\lambda$ and observe the effects on the training error and the validation error. For each $\\lambda$ save the training error, validation error, and ${\\bf w}$ \n",
    "\n",
    "\n",
    "Finish writing the code below to observe what happens when we apply L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eQDen0lL_VT"
   },
   "outputs": [],
   "source": [
    "d=10\n",
    "print('Order: ', d)\n",
    "poly = PolynomialFeatures(d)\n",
    "X_tr_poly = poly.fit_transform(X_tr) # transforms the training data\n",
    "X_val_poly =poly.fit_transform(X_val) # transforms the validation data\n",
    "\n",
    "validation_costs_10 = []\n",
    "train_costs_10 = []\n",
    "w_dict_10 = {}\n",
    "\n",
    "lambda_values = np.logspace(-10, 1,10) # After finding the best lambda value, we should go and try more lambda values near the best one we have tried.  However, our goal here to show how regularization works - so we will skip that step. \n",
    "\n",
    "for lambda1 in lambda_values:\n",
    "    \n",
    "    # TODO Q10\n",
    "    # Use your function from part 1 to determine w.\n",
    "    w = ...\n",
    "    w_dict_10[lambda1] = ... # save w for the current value of lambda1\n",
    "    \n",
    "    # predict yhat for the training data, compute E_in (MSE for the training data) and store E_in in train_costs\n",
    "    yhat =...\n",
    "    E_in = ...\n",
    "    train_costs_10.append(...)\n",
    "\n",
    "    # predict yhat_val for the validation data, compute E_val (MSE for the validation data) and store E_val in validation_costs\n",
    "    yhat_val = ...\n",
    "    E_val = ...\n",
    "    validation_costs_10.append(...)\n",
    "    \n",
    "    print('w: ', w)\n",
    "    print(\"Training size\", X_tr_poly.shape)\n",
    "\n",
    "    print('lambda:', np.around(lambda1,10))\n",
    "    print('E_in: ',E_in)\n",
    "    print(\"E_val:\", E_val)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykjPSpmrZ5C0"
   },
   "source": [
    "When lambda1 = 10.0, the errors should be close to:\n",
    "\n",
    "lambda: 10.0\n",
    "\n",
    "E_in:  0.4764905896187775\n",
    "\n",
    "E_val 55.70512695896246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cdOQMtAL_VW"
   },
   "source": [
    "###  B) Plot the different hypotheis and the training dataset to visually observe the effect of L2 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utycOnppL_VX"
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(d)\n",
    "xp = np.linspace(-5,5,200).reshape((200,1))\n",
    "xp_d = poly.fit_transform(xp)\n",
    "# TODO Q11\n",
    "\n",
    "for lambda1 in lambda_values:\n",
    "    plt.xlim([-5, 5])\n",
    "    plt.ylim([-80, 85])\n",
    "    print('lambda: ', lambda1)\n",
    "    # Plot data\n",
    "    plt.plot(X_tr,y_tr,'o')\n",
    "    \n",
    "    # Plot hypothesis as a line\n",
    "    yp_hat = ...   # type the following: xp_d.dot(w_dict[lambda1])\n",
    "    \n",
    "    # Plot hypothesis\n",
    "    plt.plot(xp,yp_hat)\n",
    "    plt.xlim(-5,5)\n",
    "\n",
    "    plt.title('Training data & model of degree '+ str(d))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNHdzIGyL_VY"
   },
   "source": [
    "###  C) Plot the learning curve for different values of $\\lambda$ (different amounts of L2 regularization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g9o43IbL_VY"
   },
   "outputs": [],
   "source": [
    "plt.ylim(0,900)\n",
    "plt.xscale(\"log\",base=10)\n",
    "\n",
    "# TODO Q12\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(...) #complete the code so it looks like plt.plot(lambda_values, train_costs,'.-')\n",
    "plt.plot(...) # now plot the validation_costs instead of the train_costs\n",
    "\n",
    "plt.title('Training and validation costs vs lambda values')\n",
    "plt.ylabel('Training and validation costs')\n",
    "plt.xlabel('lambda values')\n",
    "plt.grid(True)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sITkjuwL_VZ"
   },
   "source": [
    "# Part 4: Increasing the number of training examples\n",
    "In parts 2 and 3 we didn't use all the training data.  Here we observe what happens to the training and validation error when we add more training examples.\n",
    "\n",
    "\n",
    "In this section we will observe what happens to the training and validation errors when the number of examples is increased.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McZ_wbj8L_Va"
   },
   "outputs": [],
   "source": [
    "lambda1=0\n",
    "d=7\n",
    "print('Order: ', d)\n",
    "  \n",
    "validation_costs_13 = []\n",
    "train_costs_13 = []\n",
    "w_dict_13 = {}\n",
    "\n",
    "for i in range (N, 2*N):\n",
    "    y_tr = y_2d[0:i]\n",
    "    X_tr = X_2d[0:i]\n",
    "    poly = PolynomialFeatures(d)\n",
    "    X_tr_poly = poly.fit_transform(X_tr) # transforms the training data\n",
    "    X_val_poly =poly.transform(X_val) #  transform the validation data (Yes, this is a bit inefficient since it doesn't change from one iteration until the next. )  \n",
    "\n",
    "    # Fitting the model with a different number of training examples\n",
    "    # TODO Q13\n",
    "    # Determine w using the closed form solution from part 1 with lambda1 = 0\n",
    "    w = ...\n",
    "    w_dict_13[i] = ... # save w when the range is 0 to i-1\n",
    "    \n",
    "    # predict yhat for the training data, compute E_in (MSE for the training data) and store E_in in train_costs\n",
    "    yhat = ...\n",
    "    E_in = ...\n",
    "    train_costs_13.append(...)\n",
    "\n",
    "    # predict yhat_val for the validation data, compute E_val (MSE for the validation data) and store E_val in validation_costs\n",
    "    yhat_val = ...\n",
    "    E_val = ...\n",
    "    validation_costs_13.append(...)\n",
    "    \n",
    "    print('w: ', w)\n",
    "    print('lambda:', np.around(lambda1,4))\n",
    "    print('Number of training examples:', X_tr_poly.shape[0])\n",
    "    print('E_in: ',E_in)\n",
    "    print(\"E_val:\", E_val)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QYDM-ajZZJW"
   },
   "source": [
    "If your code works correctly, the last three lines of your output should be close to:\n",
    "\n",
    "Number of training examples: 21\n",
    "\n",
    "E_in:  0.13978192068716794\n",
    "\n",
    "E_val: 0.15515843749674452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2HQwZ8dL_Vc"
   },
   "outputs": [],
   "source": [
    "# Because the small number of training/validation sets we have odd fluxuations due to the outsized influence of a single example.  Each example has a larger influence on the hypothesis than would be true if there were more training examples.\n",
    "plt.ylim(0,3)\n",
    "# TODO Q14\n",
    "values = np.arange(N,2*N)\n",
    "plt.plot(...) # finish the code so it looks like plt.plot(values, train_costs,'.-')\n",
    "plt.plot(...) # finish the code, but this time plot values and validation_costs\n",
    "\n",
    "plt.title('Training and validation costs vs number of examples')\n",
    "plt.ylabel('Training and validation costs')\n",
    "plt.xlabel('Number of examples')\n",
    "plt.grid(True)\n",
    "plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
